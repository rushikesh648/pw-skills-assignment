{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOvtSXJWYR05fctIQFIsMS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rushikesh648/pw-skills-assignment/blob/main/feature_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1 What is a parameter?\n",
        "\n",
        "ans: Parameters are the internal variables of a model that are learned from the training data.\n",
        "\n",
        "Q2 What is correlation?What does negative correlation mean?\n",
        "\n",
        "\n",
        "ans: Correlation is an analysis of the co-variation between two or more variables.Negative correlation is a statistical term that describes the relationship between two variables in which one variable increases while the other decreases.\n",
        "\n",
        "Q3 Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "ans: Machine learning is a branch of artificial intelligence that enables algorithms to uncover hidden patterns within datasets.The learning process, whether by a human or a machine, can be divided into four components, namely, data storage, abstraction, generalization, and evaluation.\n",
        "\n",
        "Q4 How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "ans: Loss is a value that represents the summation of errors in our model. It measures how well (or bad) our model is doing. If the errors are high, the loss will be high, which means that the model does not do a good job. Otherwise, the lower it is, the better our model works.\n",
        "\n",
        "Q5 What are continuous and categorical variables?\n",
        "\n",
        "ans: continuous variable are measurements of non-finite values,while categorical variables represent grouping.\n",
        "\n",
        "Q6 How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "ans:\n",
        ">Replacing missing values with estimated values.\n",
        "\n",
        ">Preserves sample size: Doesn’t reduce data points.\n",
        "\n",
        ">Can introduce bias: Estimated values might not be accurate.\n",
        "\n",
        "Q7 What do you mean by training and testing a dataset?\n",
        "\n",
        "ans: There are two key types of data used for machine learning training and testing data. They each have a specific function to perform when building and evaluating machine learning models.\n",
        "\n",
        "Q8 What is sklearn.preprocessing?\n",
        "\n",
        "ans: Preprocessing is a crucial step in the machine learning pipeline, as it transforms raw data into a format that is more suitable for modeling. The sklearn.preprocessing module in Scikit-Learn provides several utility functions and transformer classes to facilitate this process.\n",
        "\n",
        "Q9 What is a Test set?\n",
        "\n",
        "ans: A test dataset is a collection of data points that the model hasn't seen during its training process.\n",
        "\n",
        "Q10 How do we split data for model fitting (training and testing) in Python?\n",
        "How do you approach a Machine Learning problem?\n",
        "\n",
        "ans: some common process that we splitting the data are follows:\n",
        ">train test split\n",
        "\n",
        ">train validation test split\n",
        "\n",
        ">k-fold cross validation\n",
        "\n",
        ">stratified sampling\n",
        "\n",
        ">time primarily based split\n",
        "\n",
        "Q11 Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "ans: Before fitting any model, it is often important to conduct an exploratory data analysis (EDA) in order to check assumptions, inspect the data for anomalies (such as missing, duplicated, or mis-coded data), and inform feature selection/transformation.\n",
        "\n",
        "Q12 What is correlation?\n",
        "\n",
        "ans: Correlation is a statistical technique for determining the relationship between two variables.\n",
        "\n",
        "Q13 What does negative correlation mean?\n",
        "\n",
        "ans: Negative correlation is a statistical term that describes the relationship between two variables in which one variable increases while the other decreases.\n",
        "\n",
        "Q14 How can you find correlation between variables in Python?\n",
        "\n",
        "ans: Correlation summarizes the strength and direction of the linear (straight-line) association between two quantitative variables. Denoted by r, it takes values between -1 and +1. A positive value for r indicates a positive association, and a negative value for r indicates a negative association. The closer r is to 1 the closer the data points fall to a straight line, thus, the linear association is stronger. The closer r is to 0, making the linear association weaker.\n",
        "\n",
        "Q15 What is causation? Explain difference between correlation and causation with an example.\n",
        "\n",
        "ans: Correlation means there is a statistical association between variables. Causation means that a change in one variable causes a change in another variable.\n",
        "\n",
        ">Example: Directionality problem\n",
        "\n",
        "The variables of physical activity and self esteem can be causally related in three ways:\n",
        "\n",
        "Physical activity may affect self esteem\n",
        "\n",
        "Self esteem may affect physical activity\n",
        "\n",
        "Physical activity and self esteem may both affect each other\n",
        "\n",
        ">Example: Testing directionality in an experimental design\n",
        "\n",
        "You believe that physical activity level affects self esteem, so you test this hypothesis in an experiment. You apply a physical activity intervention and measure changes in self esteem. To establish directionality, your physical activity intervention has to come before any observed change in self esteem.\n",
        "To test whether this relationship is bidirectional, you’ll need to design a new experiment assessing whether self esteem can impact physical activity level.\n",
        "\n",
        "Q16 What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "ans: Optimizers are algorithms that adjust the parameters of a neural network to minimize the loss function, thereby improving the model’s performance.\n",
        "\n",
        ">TYPES OF OPTIMIZERS :\n",
        "\n",
        "1.Gradient Descent-\n",
        "\n",
        "Example: In a simple linear regression problem, Gradient Descent can be used to find the optimal slope and intercept that minimize prediction errors.\n",
        "\n",
        "2.Stochastic Gradient Descent-\n",
        "\n",
        "Example: SGD is widely used in training deep neural networks where datasets are too large to fit into memory.\n",
        "\n",
        "3.Adagrad-\n",
        "\n",
        "Example: Adagrad works well for sparse data scenarios, such as text classification tasks using bag-of-words representations.\n",
        "\n",
        "4.Adadelta-\n",
        "\n",
        "At each iteration, first the weighted average is calculated. Where we have the restricting term(gamma = 0.95) which helps in avoiding the problem of Vanishing Gradient.\n",
        "\n",
        "5.RMSprop-\n",
        "\n",
        "Example: RMSprop is often used in recurrent neural networks (RNNs) due to its ability to handle sequences effectively.\n",
        "\n",
        "6.Adam-\n",
        "\n",
        "Example: Adam is widely regarded as one of the best optimizers for various tasks due to its efficiency and ease of use across different types of neural networks.\n",
        "\n",
        "Q17 What is sklearn.linear_model ?\n",
        "\n",
        "ans: linear_model is a class of the sklearn module if contain different functions for performing machine learning with linear models.\n",
        "\n",
        "The term linear model implies that the model is specified as a linear combination of features. Based on training data, the learning process computes one weight for each feature to form a model that can predict or estimate the target value.\n",
        "\n",
        "Q18 What does model.fit() do? What arguments must be given?\n",
        "\n",
        "ans: The fit() method in Scikit-Learn is essential for training machine learning models. It takes the input data and adjusts the model parameters to learn patterns and relationships. By understanding the workings of the fit() method, you can effectively train various machine learning models and optimize their performance. Proper data preprocessing, model selection, and evaluation techniques are vital to successful model training and deployment.it pass arguments that fit() is x train and y train.\n",
        "\n",
        "Q19 What does model.predict() do? What arguments must be given?\n",
        "\n",
        "ans:\n",
        ">What model.predict Does:\n",
        "\n",
        "Generates Predictions: It takes input data and outputs predictions based on the trained model. These predictions could be class labels, probabilities, or continuous values, depending on the type of model and task (e.g., classification, regression).\n",
        "\n",
        ">Common Arguments for model.predict:\n",
        "\n",
        ">Input Data: The primary argument is the input data for which you want to generate predictions. This could be a NumPy array, a list, or a Pandas DataFrame, depending on the framework and the model's requirements.\n",
        "\n",
        ">Batch Size (optional): Specifies the number of samples per batch of computation. This can help manage memory usage.\n",
        "\n",
        ">Verbose (optional): Controls the verbosity of the output. If set to 1, it will display a progress bar; if set to 0, it will be silent.\n",
        "\n",
        ">Steps (optional): Total number of steps (batches of samples) before declaring the prediction round finished. Useful for generators or tf.data datasets.\n",
        "\n",
        "Q20 What are continuous and categorical variables?\n",
        "\n",
        "ans: continuous variable are measurements of non-finite values,while categorical variables represent grouping.\n",
        "\n",
        "Q21 What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "ans: Feature scaling is a crucial preprocessing step in machine learning that transforms feature values to a similar scale, ensuring all features contribute equally to the model. This process is essential for datasets with features of varying ranges, units, or magnitudes.\n",
        "\n",
        "Q22 How do we perform scaling in Python?\n",
        "\n",
        "ans: Scaling in Python is commonly performed using libraries such as scikit-learn and pandas.\n",
        "\n",
        "Q23 What is sklearn.preprocessing?\n",
        "\n",
        "ans: Preprocessing is a crucial step in the machine learning pipeline, as it transforms raw data into a format that is more suitable for modeling. The sklearn.preprocessing module in Scikit-Learn provides several utility functions and transformer classes to facilitate this process.\n",
        "\n",
        "Q24 How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "ans: Splitting data into training and testing sets is a crucial step in building a machine learning model. In Python, you can use the train_test_split function from the scikit-learn library to achieve this. Here's a simple example to guide you through the process:"
      ],
      "metadata": {
        "id": "KP91-f1GQigd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "JCKfEsihk-Rk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'feature1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    'feature2': [11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
        "    'target': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "X = df[['feature1', 'feature2']]\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(\"X_train:\\n\", X_train)\n",
        "print(\"X_test:\\n\", X_test)\n",
        "print(\"y_train:\\n\", y_train)\n",
        "print(\"y_test:\\n\", y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BE5-t3QHlHe8",
        "outputId": "601cc48f-8f30-48b5-8f1e-8f7a8f0f4ddf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:\n",
            "    feature1  feature2\n",
            "5         6        16\n",
            "0         1        11\n",
            "7         8        18\n",
            "2         3        13\n",
            "9        10        20\n",
            "4         5        15\n",
            "3         4        14\n",
            "6         7        17\n",
            "X_test:\n",
            "    feature1  feature2\n",
            "8         9        19\n",
            "1         2        12\n",
            "y_train:\n",
            " 5    1\n",
            "0    0\n",
            "7    1\n",
            "2    0\n",
            "9    1\n",
            "4    0\n",
            "3    1\n",
            "6    0\n",
            "Name: target, dtype: int64\n",
            "y_test:\n",
            " 8    0\n",
            "1    1\n",
            "Name: target, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q25 Explain data encoding?\n",
        "\n",
        "ans: Encoding data refers to the conversion of categorical or text data into a numerical format that can be easily understood and processed by algorithms."
      ],
      "metadata": {
        "id": "80KWSTiTlpx7"
      }
    }
  ]
}